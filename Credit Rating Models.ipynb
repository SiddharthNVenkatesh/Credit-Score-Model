{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d42298a",
   "metadata": {},
   "source": [
    "### Credit Rating Models\n",
    "\n",
    "This notebook builds a model to predict good/bad credit for customers using financial and education data. The data was obtained from [this Kaggle page](https://www.kaggle.com/rikdifos/credit-card-approval-prediction). We cleaned the data and did some exploratory analysis in separate notebooks. The goal here is to build a few different models on the data and compare them in terms of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b2ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a0a03",
   "metadata": {},
   "source": [
    "Let's begin by importing the main dataset we will work with. This dataset has rescaled continuous features and a one in K encoding of multiclass categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7576837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0' 'ID' 'Gender' 'Car' 'Property' 'Children' 'Income' 'Age'\n",
      " 'Employment_Length' 'Mobile_Phone' 'Work_Phone' 'Phone' 'Email'\n",
      " 'Family_Size' 'IDList' '6_Month' '12_Month' '24_Month' 'Lifetime'\n",
      " 'Income_Type_Commercial associate' 'Income_Type_Pensioner'\n",
      " 'Income_Type_State servant' 'Income_Type_Student' 'Income_Type_Working'\n",
      " 'Education_Academic degree' 'Education_Higher education'\n",
      " 'Education_Incomplete higher' 'Education_Lower secondary'\n",
      " 'Education_Secondary / secondary special'\n",
      " 'Marriage_Status_Civil marriage' 'Marriage_Status_Married'\n",
      " 'Marriage_Status_Separated' 'Marriage_Status_Single / not married'\n",
      " 'Marriage_Status_Widow' 'Housing_Co-op apartment'\n",
      " 'Housing_House / apartment' 'Housing_Municipal apartment'\n",
      " 'Housing_Office apartment' 'Housing_Rented apartment'\n",
      " 'Housing_With parents' 'Occupation_Accountants'\n",
      " 'Occupation_Cleaning staff' 'Occupation_Cooking staff'\n",
      " 'Occupation_Core staff' 'Occupation_Drivers' 'Occupation_HR staff'\n",
      " 'Occupation_High skill tech staff' 'Occupation_IT staff'\n",
      " 'Occupation_Laborers' 'Occupation_Low-skill Laborers'\n",
      " 'Occupation_Managers' 'Occupation_Medicine staff' 'Occupation_Null'\n",
      " 'Occupation_Private service staff' 'Occupation_Realty agents'\n",
      " 'Occupation_Sales staff' 'Occupation_Secretaries'\n",
      " 'Occupation_Security staff' 'Occupation_Waiters/barmen staff']\n"
     ]
    }
   ],
   "source": [
    "with open(\"feature_dataframe_with_one_in_K.csv\", \"r\") as features:\n",
    "    dataframe = pd.read_csv(features)\n",
    "\n",
    "print(dataframe.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1030fd",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "In the notebook on Exploratory Analysis, we computed information values for our features. We will want to remove features that have very low information value as those mostly add noise to a logistic regression model. As such, we will only keep the following features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f7a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Property', 'Income', 'Age', 'Employment_Length', 'Email', 'Family_Size', 'Income_Type_Commercial associate', \n",
    "            'Income_Type_Pensioner', 'Income_Type_State servant', 'Income_Type_Student', 'Income_Type_Working', 'Education_Academic degree',\n",
    "            'Education_Higher education', 'Education_Incomplete higher', 'Education_Lower secondary', 'Education_Secondary / secondary special', \n",
    "            'Marriage_Status_Civil marriage', 'Marriage_Status_Married', 'Marriage_Status_Separated', 'Marriage_Status_Single / not married',\n",
    "            'Marriage_Status_Widow', 'Housing_Co-op apartment', 'Housing_House / apartment', 'Housing_Municipal apartment',\n",
    "            'Housing_Office apartment', 'Housing_Rented apartment', 'Housing_With parents', 'Occupation_Accountants', 'Occupation_Cleaning staff',\n",
    "            'Occupation_Cooking staff', 'Occupation_Core staff', 'Occupation_Drivers', 'Occupation_HR staff', 'Occupation_High skill tech staff', \n",
    "            'Occupation_IT staff',  'Occupation_Laborers', 'Occupation_Low-skill Laborers',  'Occupation_Managers', 'Occupation_Medicine staff',\n",
    "            'Occupation_Null', 'Occupation_Private service staff', 'Occupation_Realty agents', 'Occupation_Sales staff', 'Occupation_Secretaries',\n",
    "            'Occupation_Security staff', 'Occupation_Waiters/barmen staff']\n",
    " \n",
    "\n",
    "labels = ['Lifetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847639ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame = dataframe.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b86f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_frame = dataframe.loc[:, labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581d1e2",
   "metadata": {},
   "source": [
    "We have a good amount of datapoints in our dataset so we can be pretty aggressive about cutting up our data and cross-validating to parameter tune. So, our strategy will be as follows. First, we split the data into a training set and a test set. Since our classes are slightly imbalanced, we will use synthetic oversampling (SMOTE) to even out the classes in the training set. We will also run a GridSearchCV on the training set to tune our logistic regression hyperparameters, optimizing for f1_score. After finding the optimal parameters, we will train our model on the entire training set and then test the precision and recall on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6255ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = feature_frame.to_numpy()\n",
    "labels_array = labels_frame.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a293e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features_array, labels_array, test_size=0.3, \n",
    "                                                                             stratify = labels_array, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e06f8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = labels_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2877e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82fd2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_parameters = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                        'max_iter': [1000, 10000, 100000]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21bba4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('sampling', SMOTE()), ('classification', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f9d7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(LogisticRegression(), logistic_parameters, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b81d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ..............C=0.1, max_iter=1000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..............C=0.1, max_iter=1000;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ..............C=0.1, max_iter=1000;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ..............C=0.1, max_iter=1000;, score=0.006 total time=   0.1s\n",
      "[CV 5/5] END ..............C=0.1, max_iter=1000;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .............C=0.1, max_iter=10000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .............C=0.1, max_iter=10000;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .............C=0.1, max_iter=10000;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .............C=0.1, max_iter=10000;, score=0.006 total time=   0.1s\n",
      "[CV 5/5] END .............C=0.1, max_iter=10000;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ............C=0.1, max_iter=100000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ............C=0.1, max_iter=100000;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ............C=0.1, max_iter=100000;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ............C=0.1, max_iter=100000;, score=0.006 total time=   0.1s\n",
      "[CV 5/5] END ............C=0.1, max_iter=100000;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ................C=1, max_iter=1000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ................C=1, max_iter=1000;, score=0.018 total time=   0.1s\n",
      "[CV 3/5] END ................C=1, max_iter=1000;, score=0.018 total time=   0.1s\n",
      "[CV 4/5] END ................C=1, max_iter=1000;, score=0.018 total time=   0.1s\n",
      "[CV 5/5] END ................C=1, max_iter=1000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END ...............C=1, max_iter=10000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ...............C=1, max_iter=10000;, score=0.018 total time=   0.1s\n",
      "[CV 3/5] END ...............C=1, max_iter=10000;, score=0.018 total time=   0.1s\n",
      "[CV 4/5] END ...............C=1, max_iter=10000;, score=0.018 total time=   0.1s\n",
      "[CV 5/5] END ...............C=1, max_iter=10000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END ..............C=1, max_iter=100000;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..............C=1, max_iter=100000;, score=0.018 total time=   0.1s\n",
      "[CV 3/5] END ..............C=1, max_iter=100000;, score=0.018 total time=   0.1s\n",
      "[CV 4/5] END ..............C=1, max_iter=100000;, score=0.018 total time=   0.1s\n",
      "[CV 5/5] END ..............C=1, max_iter=100000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END ...............C=10, max_iter=1000;, score=0.006 total time=   0.2s\n",
      "[CV 2/5] END ...............C=10, max_iter=1000;, score=0.023 total time=   0.2s\n",
      "[CV 3/5] END ...............C=10, max_iter=1000;, score=0.018 total time=   0.2s\n",
      "[CV 4/5] END ...............C=10, max_iter=1000;, score=0.023 total time=   0.2s\n",
      "[CV 5/5] END ...............C=10, max_iter=1000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END ..............C=10, max_iter=10000;, score=0.006 total time=   0.2s\n",
      "[CV 2/5] END ..............C=10, max_iter=10000;, score=0.023 total time=   0.2s\n",
      "[CV 3/5] END ..............C=10, max_iter=10000;, score=0.018 total time=   0.2s\n",
      "[CV 4/5] END ..............C=10, max_iter=10000;, score=0.023 total time=   0.2s\n",
      "[CV 5/5] END ..............C=10, max_iter=10000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END .............C=10, max_iter=100000;, score=0.006 total time=   0.2s\n",
      "[CV 2/5] END .............C=10, max_iter=100000;, score=0.023 total time=   0.2s\n",
      "[CV 3/5] END .............C=10, max_iter=100000;, score=0.018 total time=   0.2s\n",
      "[CV 4/5] END .............C=10, max_iter=100000;, score=0.023 total time=   0.2s\n",
      "[CV 5/5] END .............C=10, max_iter=100000;, score=0.029 total time=   0.2s\n",
      "[CV 1/5] END ..............C=100, max_iter=1000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END ..............C=100, max_iter=1000;, score=0.023 total time=   0.3s\n",
      "[CV 3/5] END ..............C=100, max_iter=1000;, score=0.018 total time=   0.3s\n",
      "[CV 4/5] END ..............C=100, max_iter=1000;, score=0.023 total time=   0.3s\n",
      "[CV 5/5] END ..............C=100, max_iter=1000;, score=0.029 total time=   0.3s\n",
      "[CV 1/5] END .............C=100, max_iter=10000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END .............C=100, max_iter=10000;, score=0.023 total time=   0.3s\n",
      "[CV 3/5] END .............C=100, max_iter=10000;, score=0.018 total time=   0.3s\n",
      "[CV 4/5] END .............C=100, max_iter=10000;, score=0.023 total time=   0.3s\n",
      "[CV 5/5] END .............C=100, max_iter=10000;, score=0.029 total time=   0.3s\n",
      "[CV 1/5] END ............C=100, max_iter=100000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END ............C=100, max_iter=100000;, score=0.023 total time=   0.3s\n",
      "[CV 3/5] END ............C=100, max_iter=100000;, score=0.018 total time=   0.3s\n",
      "[CV 4/5] END ............C=100, max_iter=100000;, score=0.023 total time=   0.3s\n",
      "[CV 5/5] END ............C=100, max_iter=100000;, score=0.029 total time=   0.3s\n",
      "[CV 1/5] END .............C=1000, max_iter=1000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END .............C=1000, max_iter=1000;, score=0.023 total time=   0.4s\n",
      "[CV 3/5] END .............C=1000, max_iter=1000;, score=0.018 total time=   0.4s\n",
      "[CV 4/5] END .............C=1000, max_iter=1000;, score=0.023 total time=   0.4s\n",
      "[CV 5/5] END .............C=1000, max_iter=1000;, score=0.029 total time=   0.3s\n",
      "[CV 1/5] END ............C=1000, max_iter=10000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END ............C=1000, max_iter=10000;, score=0.023 total time=   0.4s\n",
      "[CV 3/5] END ............C=1000, max_iter=10000;, score=0.018 total time=   0.4s\n",
      "[CV 4/5] END ............C=1000, max_iter=10000;, score=0.023 total time=   0.4s\n",
      "[CV 5/5] END ............C=1000, max_iter=10000;, score=0.029 total time=   0.3s\n",
      "[CV 1/5] END ...........C=1000, max_iter=100000;, score=0.006 total time=   0.3s\n",
      "[CV 2/5] END ...........C=1000, max_iter=100000;, score=0.023 total time=   0.4s\n",
      "[CV 3/5] END ...........C=1000, max_iter=100000;, score=0.018 total time=   0.4s\n",
      "[CV 4/5] END ...........C=1000, max_iter=100000;, score=0.023 total time=   0.4s\n",
      "[CV 5/5] END ...........C=1000, max_iter=100000;, score=0.029 total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'max_iter': [1000, 10000, 100000]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e3467a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 1000}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b30cc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_2 = SMOTE(random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e217fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled, labels_resampled = smote_2.fit_resample(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bb62c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10252 10252 5126.0\n"
     ]
    }
   ],
   "source": [
    "print(len(features_resampled), len(labels_resampled), labels_resampled.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "463fc25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, max_iter=10000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=100.0, max_iter = 10000)\n",
    "clf.fit(features_resampled, labels_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e00bd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9242400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1199  378]\n",
      " [ 999  343]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b3524f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Logistic Regression Model:  0.47572815533980584\n",
      "Recall of Logistic Regression Model:  0.2555886736214605\n",
      "Accuracy of Logistic Regression Model:  0.5282631038026722\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision of Logistic Regression Model: \", precision_score(pred, labels_test))\n",
    "print('Recall of Logistic Regression Model: ', recall_score(pred, labels_test))\n",
    "print('Accuracy of Logistic Regression Model: ', accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafaa3a6",
   "metadata": {},
   "source": [
    "We see that logistic regression doesn't really give us a great model. This was somewhat expected from how poor the information values of our features were. We want to try and improve on this model. We'll attempt to do so in a number of different ways. First, we can limit our features further. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
