{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440e2fd2",
   "metadata": {},
   "source": [
    "## In this notebook, I analyze [this Kaggle dataset](https://www.kaggle.com/rikdifos/credit-card-approval-prediction). The dataset consists of demographic and financial data for accounts at a bank (unspecified) along with a credit history of that account. The same customer at the bank may have multiple accounts attached to them. The goal of the notebook is to clean up the data and construct a label for each customer using all of their accounts as good or bad credit. This notebook will later be used to build a model to predict the credit score of customers using their demographic and financial data, to quantify the risk of opening a credit account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7dfbaa",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6b284a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb608d",
   "metadata": {},
   "source": [
    "Let's begin by loading our two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69c19473",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"application_record.csv\", \"r\") as app_data:\n",
    "    app_df = pd.read_csv(app_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1b5d806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0       5008804           M            Y               Y             0   \n",
      "1       5008805           M            Y               Y             0   \n",
      "2       5008806           M            Y               Y             0   \n",
      "3       5008808           F            N               Y             0   \n",
      "4       5008809           F            N               Y             0   \n",
      "...         ...         ...          ...             ...           ...   \n",
      "438552  6840104           M            N               Y             0   \n",
      "438553  6840222           F            N               N             0   \n",
      "438554  6841878           F            N               N             0   \n",
      "438555  6842765           F            N               Y             0   \n",
      "438556  6842885           F            N               Y             0   \n",
      "\n",
      "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0               427500.0               Working               Higher education   \n",
      "1               427500.0               Working               Higher education   \n",
      "2               112500.0               Working  Secondary / secondary special   \n",
      "3               270000.0  Commercial associate  Secondary / secondary special   \n",
      "4               270000.0  Commercial associate  Secondary / secondary special   \n",
      "...                  ...                   ...                            ...   \n",
      "438552          135000.0             Pensioner  Secondary / secondary special   \n",
      "438553          103500.0               Working  Secondary / secondary special   \n",
      "438554           54000.0  Commercial associate               Higher education   \n",
      "438555           72000.0             Pensioner  Secondary / secondary special   \n",
      "438556          121500.0               Working  Secondary / secondary special   \n",
      "\n",
      "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0             Civil marriage   Rented apartment      -12005          -4542   \n",
      "1             Civil marriage   Rented apartment      -12005          -4542   \n",
      "2                    Married  House / apartment      -21474          -1134   \n",
      "3       Single / not married  House / apartment      -19110          -3051   \n",
      "4       Single / not married  House / apartment      -19110          -3051   \n",
      "...                      ...                ...         ...            ...   \n",
      "438552             Separated  House / apartment      -22717         365243   \n",
      "438553  Single / not married  House / apartment      -15939          -3007   \n",
      "438554  Single / not married       With parents       -8169           -372   \n",
      "438555               Married  House / apartment      -21673         365243   \n",
      "438556               Married  House / apartment      -18858          -1201   \n",
      "\n",
      "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0                1                1           0           0             NaN   \n",
      "1                1                1           0           0             NaN   \n",
      "2                1                0           0           0  Security staff   \n",
      "3                1                0           1           1     Sales staff   \n",
      "4                1                0           1           1     Sales staff   \n",
      "...            ...              ...         ...         ...             ...   \n",
      "438552           1                0           0           0             NaN   \n",
      "438553           1                0           0           0        Laborers   \n",
      "438554           1                1           0           0     Sales staff   \n",
      "438555           1                0           0           0             NaN   \n",
      "438556           1                0           1           0     Sales staff   \n",
      "\n",
      "        CNT_FAM_MEMBERS  \n",
      "0                   2.0  \n",
      "1                   2.0  \n",
      "2                   2.0  \n",
      "3                   1.0  \n",
      "4                   1.0  \n",
      "...                 ...  \n",
      "438552              1.0  \n",
      "438553              1.0  \n",
      "438554              1.0  \n",
      "438555              2.0  \n",
      "438556              2.0  \n",
      "\n",
      "[438557 rows x 18 columns]\n",
      "438557\n"
     ]
    }
   ],
   "source": [
    "print(app_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4219f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credit_record.csv\", \"r\") as credit_data:\n",
    "    credit_df = pd.read_csv(credit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d71b8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID  MONTHS_BALANCE STATUS\n",
      "0        5001711               0      X\n",
      "1        5001711              -1      0\n",
      "2        5001711              -2      0\n",
      "3        5001711              -3      0\n",
      "4        5001712               0      C\n",
      "...          ...             ...    ...\n",
      "1048570  5150487             -25      C\n",
      "1048571  5150487             -26      C\n",
      "1048572  5150487             -27      C\n",
      "1048573  5150487             -28      C\n",
      "1048574  5150487             -29      C\n",
      "\n",
      "[1048575 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(credit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457e801",
   "metadata": {},
   "source": [
    "Let us see if the ID keys are all unique. If so, we want to change the index to correspond to the ID key. This will save time on later computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d6131651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438510\n"
     ]
    }
   ],
   "source": [
    "print(len(set(app_df[\"ID\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e4d44",
   "metadata": {},
   "source": [
    "This is a bit unfortunate, as we have duplicate id's. We need to check if the duplicate ids have the same remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c860b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "421211  7702516           F            N               Y             2   \n",
      "421268  7602432           M            N               Y             0   \n",
      "421349  7602432           F            N               N             0   \n",
      "421464  7836971           M            Y               N             1   \n",
      "421698  7213374           M            Y               N             0   \n",
      "...         ...         ...          ...             ...           ...   \n",
      "433158  7282535           F            N               Y             0   \n",
      "433159  7742853           M            N               Y             0   \n",
      "433217  7135270           F            N               Y             0   \n",
      "433666  7091721           F            Y               Y             0   \n",
      "433789  7618285           F            N               Y             0   \n",
      "\n",
      "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "421211          180000.0               Working  Secondary / secondary special   \n",
      "421268          315000.0  Commercial associate               Higher education   \n",
      "421349          117000.0             Pensioner               Higher education   \n",
      "421464          157500.0               Working  Secondary / secondary special   \n",
      "421698          148500.0               Working  Secondary / secondary special   \n",
      "...                  ...                   ...                            ...   \n",
      "433158           63000.0             Pensioner  Secondary / secondary special   \n",
      "433159          157500.0               Working  Secondary / secondary special   \n",
      "433217          216000.0             Pensioner  Secondary / secondary special   \n",
      "433666           90000.0  Commercial associate  Secondary / secondary special   \n",
      "433789          157500.0               Working  Secondary / secondary special   \n",
      "\n",
      "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "421211               Married  House / apartment      -11753          -1256   \n",
      "421268        Civil marriage  House / apartment      -16627          -1304   \n",
      "421349               Married  House / apartment      -24708         365243   \n",
      "421464               Married  House / apartment      -13771          -5520   \n",
      "421698               Married  House / apartment       -9950           -961   \n",
      "...                      ...                ...         ...            ...   \n",
      "433158               Married  House / apartment      -21124         365243   \n",
      "433159  Single / not married  House / apartment      -15052          -1695   \n",
      "433217               Married  House / apartment      -23113         365243   \n",
      "433666               Married  House / apartment      -14116          -2269   \n",
      "433789  Single / not married  House / apartment      -10113          -1007   \n",
      "\n",
      "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "421211           1                1           1           0     Sales staff   \n",
      "421268           1                0           1           0         Drivers   \n",
      "421349           1                0           0           0             NaN   \n",
      "421464           1                0           0           0             NaN   \n",
      "421698           1                0           1           0        Laborers   \n",
      "...            ...              ...         ...         ...             ...   \n",
      "433158           1                0           1           0             NaN   \n",
      "433159           1                0           0           0        Laborers   \n",
      "433217           1                0           0           0             NaN   \n",
      "433666           1                0           0           0  Medicine staff   \n",
      "433789           1                0           0           0        Laborers   \n",
      "\n",
      "        CNT_FAM_MEMBERS  \n",
      "421211              4.0  \n",
      "421268              2.0  \n",
      "421349              2.0  \n",
      "421464              3.0  \n",
      "421698              2.0  \n",
      "...                 ...  \n",
      "433158              2.0  \n",
      "433159              1.0  \n",
      "433217              2.0  \n",
      "433666              2.0  \n",
      "433789              1.0  \n",
      "\n",
      "[94 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "app_df_duplicate_id = app_df.duplicated(subset=\"ID\", keep=False)\n",
    "\n",
    "print(app_df[app_df_duplicate_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcd143",
   "metadata": {},
   "source": [
    "There doesn't seem to be a particularly strong pattern between accounts tied to the same id. It is possible these are joint accounts but the demographic data doesn't really line up. We also don't have any indication from the dataset on how these id's are linked to the corresponding id in the credit dataframe. Fortuantely, we don't have many duplicates of this type, so we can just remove them from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "aa42f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_df = app_df.drop_duplicates(subset=\"ID\", keep=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115feb0",
   "metadata": {},
   "source": [
    "Notice that we have yet another issue with duplicates: the same customers seem to have multiple account id's. We need to identify the cause of the duplication. It is possible these are multiple accounts for the same peron, and it is also possible these multiple accounts have different credit histories. To account for this, we create some functions that help us identify duplicate data. We first create a function that takes an index and returns all duplicates below it in the dataframe, assuming contiguous duplicates. We also create a function that returns the next index that isn't a duplicate of the given one. These will be important in constructing our label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "854c2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DuplicateList(df, index, col_list):\n",
    "    '''Parameters are a pandas dataframe, an index number and a list of column names. \n",
    "       Returns a list of all index values greater than or equal to the input index that have identical data under the given columns.\n",
    "       Assumes the duplicated data in the dataframe is contiguous.'''\n",
    "    \n",
    "    Duplicates = [index]\n",
    "    df_null = df.isnull()\n",
    "    #Testing if the latest entry checked was a duplicate.\n",
    "    is_Latest_Dupe = True\n",
    "    for i in [x for x in df.index.values if x > index]:\n",
    "        if is_Latest_Dupe:\n",
    "            Dupe_Status = True\n",
    "            for col in col_list:\n",
    "                if df_null.loc[index, col] and df_null.loc[i, col]:\n",
    "                    Dupe_Status=Dupe_Status\n",
    "                else: \n",
    "                    Dupe_Status = Dupe_Status and (df.loc[index, col]==df.loc[i, col])\n",
    "            if Dupe_Status:\n",
    "                Duplicates.append(i)\n",
    "            is_Latest_Dupe = is_Latest_Dupe and Dupe_Status\n",
    "        elif not is_Latest_Dupe:\n",
    "            break\n",
    "    \n",
    "    return Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a0ec4a",
   "metadata": {},
   "source": [
    "Let's test this on some of the values we can see in our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "31c301ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "5008804",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 5008804 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-a41018c4ef87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumns_remaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDuplicateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-320-05bd6dee521e>\u001b[0m in \u001b[0;36mDuplicateList\u001b[0;34m(df, ID, col_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mDupe_Status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mdf_null\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf_null\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0mDupe_Status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDupe_Status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3774\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 5008804"
     ]
    }
   ],
   "source": [
    "#Assigning variables to the columns of our app_df dataframe\n",
    "\n",
    "columns = app_df.columns.values.tolist()\n",
    "columns_remaining = [x for x in columns if x!='ID']\n",
    "\n",
    "print(DuplicateList(df=app_df, ID=app_df[\"ID\"].loc[0], col_list = columns_remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9f315bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[3, 4, 5, 6]\n",
      "[4, 5, 6]\n",
      "[438552]\n",
      "[438556]\n",
      "[1315, 1316, 1317]\n",
      "           ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "1315  5010298           F            N               Y             0   \n",
      "1316  5010299           F            N               Y             0   \n",
      "\n",
      "      AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "1315          135000.0  Commercial associate  Secondary / secondary special   \n",
      "1316          135000.0  Commercial associate  Secondary / secondary special   \n",
      "\n",
      "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "1315            Married  House / apartment      -14918          -1866   \n",
      "1316            Married  House / apartment      -14918          -1866   \n",
      "\n",
      "      FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "1315           1                0           0           0     Sales staff   \n",
      "1316           1                0           0           0     Sales staff   \n",
      "\n",
      "      CNT_FAM_MEMBERS  \n",
      "1315              2.0  \n",
      "1316              2.0  \n"
     ]
    }
   ],
   "source": [
    "for i in [2, 3, 4, 438552, 438556]:\n",
    "    print(DuplicateList(df=app_df, index=i, col_list=columns_remaining))\n",
    "print(DuplicateList(app_df, index=1315, col_list=columns_remaining))\n",
    "print(app_df.iloc[[1315, 1316],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4a8862a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NextNonDuplicate(df, index, col_list):\n",
    "    '''Arguments are a dataframe with contiguous duplicate data, an index value and list of columns to compare\n",
    "        for duplication.\n",
    "       Returns the index of the next datapoint that isn\\'t a duplicate of the data at index.'''\n",
    "    if index <0:\n",
    "        index = len(df.index.values)+index\n",
    "    if index >=len(df.index.values)-1:\n",
    "        return None\n",
    "    elif DuplicateList(df, index, col_list)[-1] >= len(df.index.values)-1:\n",
    "        return None\n",
    "    else:\n",
    "        return [DuplicateList(df, index, col_list)[-1]+1, df.loc[DuplicateList(df, index, col_list)[-1]+1, \"ID\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47975a85",
   "metadata": {},
   "source": [
    "We can now use the drop_duplicates method in pandas to remove duplicates from app_df, but this would create some issues. The account id's in the application data are linked to the account id's in the credit data. If we remove duplicates first, we will potentially lose information. Instead, we will adopt a different strategy. We identify the accounts that are in both dataframes and only condense each dataframe to those accounts for which we have both application data and credit data. This is a natural procedure to make here, as these are the only data points we can actually use to fit a model, as for other accounts, we either lack feature data or data to construct a label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7497ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boolean series that tracks indices of app_df whose \"ID\" keys are also in credit_df\n",
    "\n",
    "app_boolean = app_df[\"ID\"].isin(credit_df[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f000ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0       5008804           M            Y               Y             0   \n",
      "1       5008805           M            Y               Y             0   \n",
      "2       5008806           M            Y               Y             0   \n",
      "3       5008808           F            N               Y             0   \n",
      "4       5008809           F            N               Y             0   \n",
      "...         ...         ...          ...             ...           ...   \n",
      "434808  5149828           M            Y               Y             0   \n",
      "434809  5149834           F            N               Y             0   \n",
      "434810  5149838           F            N               Y             0   \n",
      "434811  5150049           F            N               Y             0   \n",
      "434812  5150337           M            N               Y             0   \n",
      "\n",
      "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0               427500.0               Working               Higher education   \n",
      "1               427500.0               Working               Higher education   \n",
      "2               112500.0               Working  Secondary / secondary special   \n",
      "3               270000.0  Commercial associate  Secondary / secondary special   \n",
      "4               270000.0  Commercial associate  Secondary / secondary special   \n",
      "...                  ...                   ...                            ...   \n",
      "434808          315000.0               Working  Secondary / secondary special   \n",
      "434809          157500.0  Commercial associate               Higher education   \n",
      "434810          157500.0             Pensioner               Higher education   \n",
      "434811          283500.0               Working  Secondary / secondary special   \n",
      "434812          112500.0               Working  Secondary / secondary special   \n",
      "\n",
      "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0             Civil marriage   Rented apartment      -12005          -4542   \n",
      "1             Civil marriage   Rented apartment      -12005          -4542   \n",
      "2                    Married  House / apartment      -21474          -1134   \n",
      "3       Single / not married  House / apartment      -19110          -3051   \n",
      "4       Single / not married  House / apartment      -19110          -3051   \n",
      "...                      ...                ...         ...            ...   \n",
      "434808               Married  House / apartment      -17348          -2420   \n",
      "434809               Married  House / apartment      -12387          -1325   \n",
      "434810               Married  House / apartment      -12387          -1325   \n",
      "434811               Married  House / apartment      -17958           -655   \n",
      "434812  Single / not married   Rented apartment       -9188          -1193   \n",
      "\n",
      "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0                1                1           0           0             NaN   \n",
      "1                1                1           0           0             NaN   \n",
      "2                1                0           0           0  Security staff   \n",
      "3                1                0           1           1     Sales staff   \n",
      "4                1                0           1           1     Sales staff   \n",
      "...            ...              ...         ...         ...             ...   \n",
      "434808           1                0           0           0        Managers   \n",
      "434809           1                0           1           1  Medicine staff   \n",
      "434810           1                0           1           1  Medicine staff   \n",
      "434811           1                0           0           0     Sales staff   \n",
      "434812           1                0           0           0        Laborers   \n",
      "\n",
      "        CNT_FAM_MEMBERS  \n",
      "0                   2.0  \n",
      "1                   2.0  \n",
      "2                   2.0  \n",
      "3                   1.0  \n",
      "4                   1.0  \n",
      "...                 ...  \n",
      "434808              2.0  \n",
      "434809              2.0  \n",
      "434810              2.0  \n",
      "434811              2.0  \n",
      "434812              1.0  \n",
      "\n",
      "[36457 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "app_df_only_including_overlap = app_df.loc[app_boolean]\n",
    "print(app_df_only_including_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681f6e8",
   "metadata": {},
   "source": [
    "Let us do the same for the credit data and only keep the overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ab4179cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_boolean = credit_df[\"ID\"].isin(app_df[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "91bbd2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID  MONTHS_BALANCE STATUS\n",
      "92938    5008804               0      C\n",
      "92939    5008804              -1      C\n",
      "92940    5008804              -2      C\n",
      "92941    5008804              -3      C\n",
      "92942    5008804              -4      C\n",
      "...          ...             ...    ...\n",
      "1048570  5150487             -25      C\n",
      "1048571  5150487             -26      C\n",
      "1048572  5150487             -27      C\n",
      "1048573  5150487             -28      C\n",
      "1048574  5150487             -29      C\n",
      "\n",
      "[777715 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_df_only_including_overlap = credit_df.loc[credit_boolean]\n",
    "print(credit_df_only_including_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbfe84",
   "metadata": {},
   "source": [
    "Even in this overlap, both dataframes still have multiple accounts for the same person. To understand what is going on, we should examine the credit dataframe to see if the credit history for duplicate accounts is the same or different. We will do this only with a few examples of duplicated data, as the dataset is fairly large. First, let us count the number of unique ids in both lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d0795859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36457\n",
      "36457\n"
     ]
    }
   ],
   "source": [
    "print(len(set(app_df_only_including_overlap[\"ID\"])))\n",
    "print(len(set(credit_df_only_including_overlap[\"ID\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e043d60",
   "metadata": {},
   "source": [
    "This is good. It tells us that each row in the condensed application data table has a unique account id at least, even if multiple accounts correspond to the same person. The condensed credit data also has these same accounts, as expected, although rows in this data are identified by both the account id and the month the account started being recorded. We next want to identify all accounts that correspond to the same person as a given account in application data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a518c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DuplicateIDs(df, ID, col_list):\n",
    "    '''Parameters are a dataframe with an ID column and a specified ID number. \n",
    "       Returns a list of IDs that have the same data as the given ID across other columns'''\n",
    "    t_0 = time.time()\n",
    "    df_ID = df.loc[df[\"ID\"]==ID]\n",
    "    index = df_ID.index.values.tolist()[0]\n",
    "    dupe_indices = DuplicateList(df, index, col_list)\n",
    "    dupe_list = []\n",
    "    for entry in df.loc[dupe_indices, \"ID\"]:\n",
    "        dupe_list.append(entry)\n",
    "    t_1 = time.time()\n",
    "    print(\"Time Elapsed :\", t_1 - t_0)\n",
    "    return dupe_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459e9b7",
   "metadata": {},
   "source": [
    "We're going to be using this function to construct our label. It will be applied many times, so we want to get a sense of how long this function takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "cf733fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1725151538848877\n",
      "Time Elapsed : 0.1752791404724121\n",
      "[5008804, 5008805]\n",
      "0.1635420322418213\n",
      "Time Elapsed : 0.16531777381896973\n",
      "[5008808, 5008809, 5008810, 5008811]\n"
     ]
    }
   ],
   "source": [
    "print(DuplicateIDs(app_df, 5008804, columns_remaining))\n",
    "\n",
    "\n",
    "print(DuplicateIDs(app_df, 5008808, columns_remaining))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484eab2b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Let's now write a function that will take our credit dataframe and extract the entries whose id numbers correspond to duplicates of a given id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "276dcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDuplicateData(ID, output_df=credit_df_only_including_overlap, identifier_df=app_df_only_including_overlap):\n",
    "    '''Parameters: ID is an id number. output_df and identifier_df are dataframes that have an ID column \n",
    "        with all ID values shared in common in both dataframes.\n",
    "       Returns: Entries in output_df that correspond to the duplicate id_values, with duplicates identified \n",
    "        via identifier_df'''\n",
    "    id_series=DuplicateIDs(identifier_df, ID)\n",
    "    \n",
    "    return output_df.loc[output_df[\"ID\"].isin(id_series)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7be2d",
   "metadata": {},
   "source": [
    "Here are some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8778c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7ffd7cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MONTHS_BALANCE STATUS\n",
      "92938  5008804               0      C\n",
      "92939  5008804              -1      C\n",
      "92940  5008804              -2      C\n",
      "92941  5008804              -3      C\n",
      "92942  5008804              -4      C\n",
      "92943  5008804              -5      C\n",
      "92944  5008804              -6      C\n",
      "92945  5008804              -7      C\n",
      "92946  5008804              -8      C\n",
      "92947  5008804              -9      C\n",
      "92948  5008804             -10      C\n",
      "92949  5008804             -11      C\n",
      "92950  5008804             -12      C\n",
      "92951  5008804             -13      1\n",
      "92952  5008804             -14      0\n",
      "92953  5008804             -15      X\n",
      "92954  5008805               0      C\n",
      "92955  5008805              -1      C\n",
      "92956  5008805              -2      C\n",
      "92957  5008805              -3      C\n",
      "92958  5008805              -4      C\n",
      "92959  5008805              -5      C\n",
      "92960  5008805              -6      C\n",
      "92961  5008805              -7      C\n",
      "92962  5008805              -8      C\n",
      "92963  5008805              -9      C\n",
      "92964  5008805             -10      C\n",
      "92965  5008805             -11      C\n",
      "92966  5008805             -12      1\n",
      "92967  5008805             -13      0\n",
      "92968  5008805             -14      X\n"
     ]
    }
   ],
   "source": [
    "print(GetDuplicateData(5008804))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "374e75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MONTHS_BALANCE STATUS\n",
      "92999  5008808               0      0\n",
      "93000  5008808              -1      X\n",
      "93001  5008808              -2      0\n",
      "93002  5008808              -3      X\n",
      "93003  5008808              -4      X\n",
      "93004  5008809             -22      X\n",
      "93005  5008809             -23      X\n",
      "93006  5008809             -24      X\n",
      "93007  5008809             -25      X\n",
      "93008  5008809             -26      X\n",
      "93009  5008810               0      C\n",
      "93010  5008810              -1      C\n",
      "93011  5008810              -2      C\n",
      "93012  5008810              -3      C\n",
      "93013  5008810              -4      C\n",
      "93014  5008810              -5      C\n",
      "93015  5008810              -6      C\n",
      "93016  5008810              -7      C\n",
      "93017  5008810              -8      C\n",
      "93018  5008810              -9      C\n",
      "93019  5008810             -10      C\n",
      "93020  5008810             -11      C\n",
      "93021  5008810             -12      C\n",
      "93022  5008810             -13      C\n",
      "93023  5008810             -14      C\n",
      "93024  5008810             -15      X\n",
      "93025  5008810             -16      0\n",
      "93026  5008810             -17      X\n",
      "93027  5008810             -18      0\n",
      "93028  5008810             -19      X\n",
      "93029  5008810             -20      0\n",
      "93030  5008810             -21      0\n",
      "93031  5008810             -22      0\n",
      "93032  5008810             -23      X\n",
      "93033  5008810             -24      0\n",
      "93034  5008810             -25      X\n",
      "93035  5008810             -26      X\n",
      "93036  5008811               0      C\n",
      "93037  5008811              -1      C\n",
      "93038  5008811              -2      C\n"
     ]
    }
   ],
   "source": [
    "print(GetDuplicateData(app_df_only_including_overlap.loc[3, \"ID\"]).iloc[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7155f208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MONTHS_BALANCE STATUS\n",
      "93039  5008811              -3      C\n",
      "93040  5008811              -4      C\n",
      "93041  5008811              -5      C\n",
      "93042  5008811              -6      C\n",
      "93043  5008811              -7      C\n",
      "93044  5008811              -8      C\n",
      "93045  5008811              -9      C\n",
      "93046  5008811             -10      C\n",
      "93047  5008811             -11      C\n",
      "93048  5008811             -12      C\n",
      "93049  5008811             -13      C\n",
      "93050  5008811             -14      C\n",
      "93051  5008811             -15      C\n",
      "93052  5008811             -16      C\n",
      "93053  5008811             -17      C\n",
      "93054  5008811             -18      C\n",
      "93055  5008811             -19      C\n",
      "93056  5008811             -20      C\n",
      "93057  5008811             -21      C\n",
      "93058  5008811             -22      C\n",
      "93059  5008811             -23      C\n",
      "93060  5008811             -24      C\n",
      "93061  5008811             -25      C\n",
      "93062  5008811             -26      C\n",
      "93063  5008811             -27      X\n",
      "93064  5008811             -28      0\n",
      "93065  5008811             -29      X\n",
      "93066  5008811             -30      0\n",
      "93067  5008811             -31      X\n",
      "93068  5008811             -32      0\n",
      "93069  5008811             -33      0\n",
      "93070  5008811             -34      0\n",
      "93071  5008811             -35      X\n",
      "93072  5008811             -36      0\n",
      "93073  5008811             -37      X\n",
      "93074  5008811             -38      X\n"
     ]
    }
   ],
   "source": [
    "print(GetDuplicateData(app_df_only_including_overlap.loc[3, \"ID\"]).iloc[40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fcef2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5008812]\n",
      "[7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(NextNonDuplicate(app_df, 3, columns_remaining))\n",
    "print(DuplicateList(app_df, 7, columns_remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4d9eece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MONTHS_BALANCE STATUS\n",
      "93075  5008812              -4      0\n",
      "93076  5008812              -5      X\n",
      "93077  5008812              -6      X\n",
      "93078  5008812              -7      0\n",
      "93079  5008812              -8      0\n",
      "93080  5008812              -9      0\n",
      "93081  5008812             -10      0\n",
      "93082  5008812             -11      0\n",
      "93083  5008812             -12      0\n",
      "93084  5008812             -13      0\n",
      "93085  5008812             -14      0\n",
      "93086  5008812             -15      0\n",
      "93087  5008812             -16      0\n",
      "93088  5008812             -17      0\n",
      "93089  5008812             -18      0\n",
      "93090  5008812             -19      0\n",
      "93091  5008812             -20      X\n",
      "93092  5008813               0      0\n",
      "93093  5008813              -1      X\n",
      "93094  5008813              -2      X\n",
      "93095  5008813              -3      0\n",
      "93096  5008813              -4      0\n",
      "93097  5008813              -5      0\n",
      "93098  5008813              -6      0\n",
      "93099  5008813              -7      0\n",
      "93100  5008813              -8      0\n",
      "93101  5008813              -9      0\n",
      "93102  5008813             -10      0\n",
      "93103  5008813             -11      0\n",
      "93104  5008813             -12      0\n",
      "93105  5008813             -13      0\n",
      "93106  5008813             -14      0\n",
      "93107  5008813             -15      0\n",
      "93108  5008813             -16      X\n",
      "93109  5008814              -1      0\n",
      "93110  5008814              -2      X\n",
      "93111  5008814              -3      X\n",
      "93112  5008814              -4      0\n",
      "93113  5008814              -5      0\n",
      "93114  5008814              -6      0\n",
      "93115  5008814              -7      0\n",
      "93116  5008814              -8      0\n",
      "93117  5008814              -9      0\n",
      "93118  5008814             -10      0\n",
      "93119  5008814             -11      0\n",
      "93120  5008814             -12      0\n",
      "93121  5008814             -13      0\n",
      "93122  5008814             -14      0\n",
      "93123  5008814             -15      0\n",
      "93124  5008814             -16      0\n",
      "93125  5008814             -17      X\n"
     ]
    }
   ],
   "source": [
    "print(GetDuplicateData(app_df_only_including_overlap.loc[7, \"ID\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bf512",
   "metadata": {},
   "source": [
    "These tables are suggesgtive. The different account ids in application data are linked to the same person, but correspond to different credit accounts with the bank the data was collected from. This suggests an approach to deal with the duplication:\n",
    "1. Use drop_duplicate to only keep the top entry in each block corresponding to a single person.\n",
    "2. Record the other account numbers of the person as a single new column in the application dataframe.\n",
    "3. Use the credit data for all accounts of this person to create a new label column in the application dataframe. \n",
    "\n",
    "Some of this may involve a lot of processing time. As a quick check on whether we can save some effort, let us see how much data we lose if we simply keep just one account per customer. This will also give us the number of customers we have data for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d6695fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_no_dupes = app_df_only_including_overlap.drop_duplicates(subset=columns_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a9ff59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0       5008804           M            Y               Y             0   \n",
      "2       5008806           M            Y               Y             0   \n",
      "3       5008808           F            N               Y             0   \n",
      "7       5008812           F            N               Y             0   \n",
      "10      5008815           M            Y               Y             0   \n",
      "...         ...         ...          ...             ...           ...   \n",
      "434797  5148694           F            N               N             0   \n",
      "434801  5149055           F            N               Y             0   \n",
      "434806  5149729           M            Y               Y             0   \n",
      "434810  5149838           F            N               Y             0   \n",
      "434812  5150337           M            N               Y             0   \n",
      "\n",
      "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0               427500.0               Working               Higher education   \n",
      "2               112500.0               Working  Secondary / secondary special   \n",
      "3               270000.0  Commercial associate  Secondary / secondary special   \n",
      "7               283500.0             Pensioner               Higher education   \n",
      "10              270000.0               Working               Higher education   \n",
      "...                  ...                   ...                            ...   \n",
      "434797          180000.0             Pensioner  Secondary / secondary special   \n",
      "434801          112500.0  Commercial associate  Secondary / secondary special   \n",
      "434806           90000.0               Working  Secondary / secondary special   \n",
      "434810          157500.0             Pensioner               Higher education   \n",
      "434812          112500.0               Working  Secondary / secondary special   \n",
      "\n",
      "          NAME_FAMILY_STATUS    NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0             Civil marriage     Rented apartment      -12005          -4542   \n",
      "2                    Married    House / apartment      -21474          -1134   \n",
      "3       Single / not married    House / apartment      -19110          -3051   \n",
      "7                  Separated    House / apartment      -22464         365243   \n",
      "10                   Married    House / apartment      -16872           -769   \n",
      "...                      ...                  ...         ...            ...   \n",
      "434797        Civil marriage  Municipal apartment      -20600           -198   \n",
      "434801               Married    House / apartment      -15837          -2694   \n",
      "434806               Married    House / apartment      -19101          -1721   \n",
      "434810               Married    House / apartment      -12387          -1325   \n",
      "434812  Single / not married     Rented apartment       -9188          -1193   \n",
      "\n",
      "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0                1                1           0           0             NaN   \n",
      "2                1                0           0           0  Security staff   \n",
      "3                1                0           1           1     Sales staff   \n",
      "7                1                0           0           0             NaN   \n",
      "10               1                1           1           1     Accountants   \n",
      "...            ...              ...         ...         ...             ...   \n",
      "434797           1                0           0           0        Laborers   \n",
      "434801           1                1           1           0             NaN   \n",
      "434806           1                0           0           0             NaN   \n",
      "434810           1                0           1           1  Medicine staff   \n",
      "434812           1                0           0           0        Laborers   \n",
      "\n",
      "        CNT_FAM_MEMBERS  \n",
      "0                   2.0  \n",
      "2                   2.0  \n",
      "3                   1.0  \n",
      "7                   1.0  \n",
      "10                  2.0  \n",
      "...                 ...  \n",
      "434797              2.0  \n",
      "434801              2.0  \n",
      "434806              2.0  \n",
      "434810              2.0  \n",
      "434812              1.0  \n",
      "\n",
      "[9728 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(app_no_dupes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2c4e8",
   "metadata": {},
   "source": [
    "We have roughly a 4:1 ratio of accounts:customers, so it will be important to track multiple accounts for the same person. To keep track of the data, we add the duplicate id's as a column to the dataframe without duplicate accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36babbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
